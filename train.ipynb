{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Train and load"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "import os\r\n",
    "import pandas as pd\r\n",
    "import xgboost as xgb\r\n",
    "from pickle import load, dump\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from warnings import filterwarnings\r\n",
    "import joblib \r\n",
    "from xgboost.training import train\r\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\r\n",
    "\r\n",
    "filterwarnings(\"ignore\")\r\n",
    "\r\n",
    "\r\n",
    "data_folder = \"data\"\r\n",
    "features_csv = os.path.join(data_folder, \"features.csv\")\r\n",
    "targets_csv = os.path.join(data_folder, \"targets.csv\")\r\n",
    "\r\n",
    "\r\n",
    "features = pd.read_csv(features_csv, index_col=0)\r\n",
    "targets = pd.read_csv(targets_csv, index_col=0)\r\n",
    "\r\n",
    "\r\n",
    "features.drop(['index','season'],axis=1,inplace=True)\r\n",
    "\r\n",
    "#le= OneHotEncoder(sparse=False)\r\n",
    "le= LabelEncoder()\r\n",
    "targets=le.fit_transform(targets)\r\n",
    "joblib.dump(le,os.path.join('models','label_encoder.joblib'))\r\n",
    "print(features.shape)\r\n",
    "print(targets.shape)\r\n",
    "\r\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(features, targets, test_size=0.3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10044, 122)\n",
      "(10044,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "\r\n",
    "dtrain = xgb.DMatrix(train_X, label=train_Y, enable_categorical=True)\r\n",
    "dtest = xgb.DMatrix(test_X, label=test_Y, enable_categorical=True)\r\n",
    "# dtrain = xgb.DMatrix(train_X, label=train_Y)\r\n",
    "# dtest = xgb.DMatrix(test_X, label=test_Y)\r\n",
    "\r\n",
    "\r\n",
    "param = {\r\n",
    "        \"verbosity\": 0,\r\n",
    "        \"objective\": \"multi:softprob\",\r\n",
    "        \"eval_metric\": \"auc\",\r\n",
    "        'num_class': 3,\r\n",
    "        \"booster\": 'gblinear',\r\n",
    "        \"lambda\": 0.996390119803819,\r\n",
    "        \"alpha\": 1.510122265371948e-08,\r\n",
    "    }\r\n",
    "\r\n",
    "num_round = 20  # the number of training iterations\r\n",
    "\r\n",
    "xgbc=xgb.train(param,dtrain,num_round)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "xgbc.eval(dtest)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[0]\\teval-auc:0.602694'"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "y_preds=xgbc.predict(dtest)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "* predictions shape n_samples*n_classes. we should encode the true values as well"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "ohe=OneHotEncoder(sparse=False)\r\n",
    "test_Y_ohe=ohe.fit_transform(test_Y.reshape(-1, 1))\r\n",
    "\r\n",
    "from sklearn.metrics import roc_auc_score\r\n",
    "roc_auc_score(test_Y_ohe,y_preds,average='weighted')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6026940012398101"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "model_file_path = os.path.join(\"models\", \"xgb_model.json\")\r\n",
    "\r\n",
    "xgbc.save_model(model_file_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, f1_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "y_preds"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "XGBoostError",
     "evalue": "[02:04:56] ..\\src\\metric\\rank_metric.cc:243: Check failed: preds.Size() == info.labels_.Size() (9042 vs. 3014) : label size predict size not match",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10748/3254141068.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxgbc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\football_betting_project\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, data, name, iteration)\u001b[0m\n\u001b[0;32m   1380\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0man\u001b[0m \u001b[0mempty\u001b[0m \u001b[0mdict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mno\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m         \"\"\"\n\u001b[1;32m-> 1382\u001b[1;33m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[0msarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m         _check_call(_LIB.XGBoosterGetAttrNames(self.handle,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\football_betting_project\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36meval_set\u001b[1;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1344\u001b[1;33m         \"\"\"Copy the booster object.\n\u001b[0m\u001b[0;32m   1345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\football_betting_project\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_log_callback_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBRegisterLogCallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [02:04:56] ..\\src\\metric\\rank_metric.cc:243: Check failed: preds.Size() == info.labels_.Size() (9042 vs. 3014) : label size predict size not match"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('football_betting_project': conda)"
  },
  "interpreter": {
   "hash": "24d33b066cbdbce1b5de503a118e89f0d52bf0fa6c1e114dfe921e04caa000dd"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}